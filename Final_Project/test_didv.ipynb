{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samuel Watkins, 3032132676\n",
    "---\n",
    "# Final Project, AY250, Spring 2018\n",
    "## Due Thursday, May 10, 5 PM\n",
    "\n",
    "This is the testing script to run the DIDV analysis suite. Below is the project proposal that I submitted on Piazza.\n",
    "\n",
    "> **Final Project Proposal**\n",
    "\n",
    ">My project proposal is to create an analysis suite for my research group. My group runs transition edge sensor (TES) detectors that operate in the superconducting transition, where the dynamics are nonlinear (but can be linearized in the small signal limit). The small signal dynamics can be used to study the physical properties of the detectors, as well as to calculate the expected energy resolution from theory (which would not be in the scope of this analysis). \n",
    "\n",
    ">The analysis suite will use an already written autocutting algorithm (to cut out data that has pulses from photons or other particles hitting the detector), fit the complex impedance of the detector in frequency space, and generate plots to show the results. If I have the time, I would also like to combine this analysis suite with one that processes the noise of a flat trace (i.e. calculates the power spectral density). I would also like to use parallel processing in this, since we can have up to ~1000 data files to analyze at a time.\n",
    "\n",
    ">We have some of these functions written up for fitting, but my idea is to vastly clean up the code/improve the comments, consolidate the various sources into one analysis suite, add the parallel processing to hopefully speed up the code by a fair amount, create nice plots, and find a good way of saving the data that isn't .pkl files (I think this would be .hdf5). This would draw on lectures about Numpy/Scipy for the math/fitting functions, Matplotlib for the plotting, Parallelism for the parallel computing, and the databases with regards to using HDF5.\n",
    "\n",
    ">Let me know if this sounds okay, or if any of you have other questions about it! Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the needed packages to run the test script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from DIDV import processDIDV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import time\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set all of the necessary parameters and load the traces from an HDF5 file in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting various parameters that are specific to the dataset\n",
    "Rshunt = 5.0e-3\n",
    "Rbias_SG = 20000.0\n",
    "Rfb = 5000.0\n",
    "loopgain = 2.4\n",
    "ADCperVolt = 65536.0/2.0\n",
    "fs = 625.0e3\n",
    "sgFreq = 100.0\n",
    "sgAmp = 0.009381 /Rbias_SG\n",
    "drivergain = 4.0\n",
    "Rp = 0.0060367199999999998\n",
    "Rload = Rshunt+Rp\n",
    "dRload = 0.0001\n",
    "R0 = 0.075570107054005367\n",
    "dR0 = 8.96383052e-04\n",
    "\n",
    "convToAmps = Rfb * loopgain * drivergain * ADCperVolt\n",
    "\n",
    "saveResults = True\n",
    "\n",
    "# load the dataset\n",
    "with h5py.File('example_traces.h5','r') as f:\n",
    "    rawTraces = np.array(f[\"rawTraces\"])\n",
    "\n",
    "fileSaveName = \"example_traces_data\"\n",
    "\n",
    "# set the priors information, for use the priors fitting\n",
    "priors = np.zeros(7)\n",
    "invpriorsCov = np.zeros((7,7))\n",
    "priors[0] = Rload\n",
    "priors[1] = R0\n",
    "invpriorsCov[0,0] = 1.0/dRload**2\n",
    "invpriorsCov[1,1] = 1.0/dR0**2\n",
    "dt0=-18.8e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the processing package on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Starting processing...')\n",
    "savedData = processDIDV(rawTraces,priors=priors,invpriorsCov=invpriorsCov,timeOffset=0,\n",
    "                        dt0=dt0,traceGain=convToAmps,sgFreq=sgFreq,sgAmp=sgAmp,\n",
    "                        fs=fs,dutycycle=0.5,add180Phase=False,fit=True,autoCut=False,\n",
    "                        pathSave='',fileStr=fileSaveName,makePlots=True,\n",
    "                        saveResults=saveResults,R0=R0,dR0=dR0,Rp=Rp,dRp=dRload,Rsh=Rshunt)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's look at the plots to make sure it's working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
