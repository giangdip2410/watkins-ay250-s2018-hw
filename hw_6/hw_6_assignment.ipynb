{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samuel Watkins, 3032132676"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6: Homebrew Computer Vision\n",
    "## Due Monday Apr 2, 2018 at 2 PM\n",
    "\n",
    "1. Download the [zip file](https://www.dropbox.com/s/cst9awcjpp08k33/50_categories.tar.gz). Look at some of the images, noting that there are 50 classes in 4244 images (e.g. \"goldfish\", “llama”, “speed-boat”, ...). Caution: it’s a pretty large file (~208M).\n",
    "2. Write a set of methods that takes as input one of these images, and then computes real-numbered features as the return. You should produce at least 15 features.\n",
    "3. Based on the feature set for each image, build a random forest classifier. Produce metrics on your estimated error rates using cross-validation. How much better is this than the expectation with random guessing? What are the 3 most important features?\n",
    "4. Make sure your final classifier can run on a directory of different images, where a call like `run_final_classifier(\"/new/directory/path/\")` on a directory that contains files like `validation1.jpg`, `validation2.jpg`, etc. will produce an output file that looks like:  \n",
    "```\n",
    "filename              predicted_class  \n",
    "``` \n",
    "` `-----------------------------------------------------------------\n",
    "```\n",
    "validation1.jpg       unicorn  \n",
    "validation2.jpg       camel  \n",
    "```\n",
    "\n",
    "    We will have a validation set to test how good your classifier is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Extract Features from an Image\n",
    "We have written a function that takes in a path to an image and extracts 33 different features to be used to train a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.feature import corner_harris,peak_local_max,canny,corner_peaks,blob_doh\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color.colorconv import rgb2grey,grey2rgb\n",
    "from skimage.filters import frangi,gaussian,threshold_li\n",
    "from skimage.transform import rescale,hough_line,hough_line_peaks\n",
    "from skimage.measure import shannon_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractImageFeatures(pathToImage,smallImageSize=16000.0):\n",
    "    \"\"\"\n",
    "    Feature Extraction Function\n",
    "    \n",
    "        This function takes a path to an image, reads the image into a numpy array, \n",
    "        and does various analyses on the image to extract features. These analyses range from aspect ratio \n",
    "        to Shannon entropy. The output is a numpy array that stores each extracted feature as a single number. \n",
    "        For many of the features, the image will be scaled down by a factor determined by the parameter smallImageSize,\n",
    "        which is done to speed up the code.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pathToImage : str\n",
    "        The path to the image from which we will extract features from.\n",
    "    smallImageSize : float\n",
    "        The area in pixels of the scaled-down image from which certain features will be extracted from.\n",
    "        By default, this is set to be 16000 (units of pixels**2)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    features : numpy.ndarray\n",
    "        An array of floats containing each feature that was extracted from the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    # read in the image as a numpy array\n",
    "    imageArray = plt.imread(pathToImage).astype(\"float\")\n",
    "    \n",
    "    # if the image is already greyscale, then convert it to and RGB array\n",
    "    if len(imageArray.shape)<3:\n",
    "        imageArray = grey2rgb(imageArray)\n",
    "    # convert the image to greyscale\n",
    "    greyImgArr = rgb2grey(imageArray)\n",
    "    # calculate the scale factor that will scale the image to the size specificed by smallImageSize\n",
    "    scaleFactor = np.sqrt(smallImageSize/np.prod(greyImgArr.shape))\n",
    "    # scale down the greyscale and RGB images \n",
    "    imgScaled = rescale(greyImgArr,scaleFactor,mode = \"constant\")\n",
    "    imgScaledColor = rescale(imageArray,scaleFactor,mode = \"constant\")\n",
    "    # apply a gaussian filter to the greyscale image for smoothing\n",
    "    imgScaledGauss = gaussian(imgScaled)\n",
    "    \n",
    "    # calculate the area, height, width, and aspect ratio of the image\n",
    "    imgSize = np.prod(greyImgArr.shape)\n",
    "    imgHeight = greyImgArr.shape[0]\n",
    "    imgWidth = greyImgArr.shape[1]\n",
    "    aspectRatio = imgWidth/imgHeight\n",
    "    \n",
    "    # find the average value of all of the RGB channels\n",
    "    avgAllChans = np.mean(imageArray)\n",
    "    \n",
    "    # find the average value of each of the RGB channels\n",
    "    avgRedChan = np.mean(imageArray[:,:,0])\n",
    "    avgGreenChan = np.mean(imageArray[:,:,1])\n",
    "    avgBlueChan = np.mean(imageArray[:,:,2])\n",
    "    \n",
    "    # calculate the ratios of the average value of each channel\n",
    "    ratioRedBlue = avgRedChan/avgBlueChan\n",
    "    ratioBlueGreen = avgBlueChan/avgGreenChan\n",
    "    ratioRedGreen = avgRedChan/avgGreenChan\n",
    "    \n",
    "    # apply a corner detection algorithm to count how many corners there are in the image\n",
    "    corners = corner_harris(imgScaled)\n",
    "    numCorners = len(corner_peaks(corners))\n",
    "    \n",
    "    # calculate the number of peaks in the image\n",
    "    peaks = peak_local_max(imgScaled)\n",
    "    numPeaks = len(peaks)\n",
    "    \n",
    "    # apply segmentation algorithm to find the number of segments in the image\n",
    "    segments = slic(imgScaled)\n",
    "    numSegments = np.max(segments)\n",
    "    \n",
    "    # apply an edge detection algorithm to calculate the length of the edges\n",
    "    edges = canny(frangi(imgScaledGauss))\n",
    "    edgeLength = np.sum(edges)\n",
    "    if edgeLength == 0:\n",
    "        edgeLength+=1\n",
    "    \n",
    "    # zoom in to the middle of the picture to calculate the ratio of edges in the middle to the total edge length\n",
    "    edgesZoomed = edges[int(imgScaled.shape[0]/4):-int(imgScaled.shape[0]/4),\n",
    "                        int(imgScaled.shape[1]/4):-int(imgScaled.shape[1]/4)]\n",
    "    edgesInMiddle = np.sum(edgesZoomed)/edgeLength\n",
    "    \n",
    "    # apply a line detection algorithm to count the approximate number of lines in the edges\n",
    "    hspace,angles,distances = hough_line(edges)\n",
    "    if np.sum(hspace)>0:\n",
    "        numLines = len(hough_line_peaks(hspace,angles,distances)[0])\n",
    "    else:\n",
    "        numLines = 0\n",
    "    \n",
    "    # take the ratio of number of lines to edge length\n",
    "    ratioLinesEdges = numLines/edgeLength\n",
    "    \n",
    "    # calculate how many times a vertical and horizontal line through the image crosses a detected edge\n",
    "    horizontalEdges = edges[int(edges.shape[0]/2)]\n",
    "    verticalEdges = edges[:,int(edges.shape[1]/2)]\n",
    "    horizontalEdgeCrossings = sum(horizontalEdges[:-1]!=horizontalEdges[1:])\n",
    "    verticalEdgeCrossings = sum(verticalEdges[:-1]!=verticalEdges[1:])\n",
    "\n",
    "    # take ratios of corners, peaks, segments, and edge length\n",
    "    ratioCornersPeak = numCorners/numPeaks\n",
    "    ratioCornersSegments = numCorners/numSegments\n",
    "    ratioCornersEdges = numCorners/edgeLength\n",
    "    ratioPeaksSegments = numPeaks/numSegments\n",
    "    ratioPeaksEdges = numPeaks/edgeLength\n",
    "    ratioSegmentsEdges = numSegments/edgeLength\n",
    "    \n",
    "    # calculate the shannon entropy of the image\n",
    "    shanent = shannon_entropy(imageArray)\n",
    "    \n",
    "    # apply a threshold algorithm to determine the foreground of the image and the size of the foreground\n",
    "    thresh = threshold_li(imgScaled)\n",
    "    foreground = imgScaled <=thresh\n",
    "    foregroundSize = np.sum(foreground)\n",
    "    \n",
    "    # take the ratio of foreground size to edge length\n",
    "    ratioForegroundEdge = foregroundSize/edgeLength\n",
    "    \n",
    "    # take the ratio of the edge length of the foreground to the edge length of the entire image\n",
    "    edgeRatio = np.sum(canny(gaussian(foreground)))/edgeLength\n",
    "    \n",
    "    # find the average colors in the foreground\n",
    "    avgForegroundRed = np.mean(imgScaledColor[:,:,0][foreground])\n",
    "    avgForegroundGreen = np.mean(imgScaledColor[:,:,1][foreground])\n",
    "    avgForegroundBlue = np.mean(imgScaledColor[:,:,2][foreground])\n",
    "    \n",
    "    # take the ratios of the average foreground colors\n",
    "    ratioFGRedGreen = avgForegroundRed/avgForegroundGreen\n",
    "    ratioFGRedBlue = avgForegroundRed/avgForegroundBlue\n",
    "    ratioFGGreenBlue = avgForegroundGreen/avgForegroundBlue\n",
    "    \n",
    "    # store all values in an array\n",
    "    features=np.array([aspectRatio,ratioRedBlue,ratioBlueGreen,\n",
    "                        ratioRedGreen,numPeaks,numSegments,edgeLength,\n",
    "                        horizontalEdgeCrossings,verticalEdgeCrossings,\n",
    "                        ratioCornersPeak,ratioCornersSegments,ratioPeaksSegments,\n",
    "                        ratioPeaksEdges,ratioSegmentsEdges,shanent,thresh,foregroundSize,\n",
    "                        avgForegroundRed,avgForegroundGreen,avgForegroundBlue,\n",
    "                        ratioFGRedGreen,ratioFGRedBlue,ratioFGGreenBlue,numLines,\n",
    "                        ratioCornersEdges,avgAllChans,avgRedChan,avgGreenChan,avgBlueChan,\n",
    "                        edgeRatio,edgesInMiddle,ratioLinesEdges,ratioForegroundEdge])\n",
    "    \n",
    "    # if any feature is nan or inf, set it to zero\n",
    "    features[np.isnan(features)]=0.0\n",
    "    features[np.isinf(features)]=0.0\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import blob_doh,shape_index\n",
    "from copy import deepcopy\n",
    "from skimage.filters import try_all_threshold,threshold_minimum\n",
    "from skimage.color import label2rgb\n",
    "from skimage.segmentation import random_walker\n",
    "\n",
    "\n",
    "pathToImage = \"/home/sam/Documents/watkins-ay250-s2018-hw/hw_6/50_categories/bear/bear_0012.jpg\"\n",
    "imageArray = plt.imread(pathToImage).astype(\"float\")\n",
    "imageArray = grey2rgb(imageArray)\n",
    "greyImgArr = rgb2grey(imageArray)\n",
    "scaleFactor = np.sqrt(16000.0/np.prod(greyImgArr.shape))\n",
    "imgScaledColor = rescale(imageArray,scaleFactor,mode = \"constant\")\n",
    "imgScaled = rescale(greyImgArr,scaleFactor,mode = \"constant\")\n",
    "threshval = threshold_otsu(gaussian(imgScaled))\n",
    "imgBackground = gaussian(imgScaled) > threshval\n",
    "imgForeground = deepcopy(imgScaled)\n",
    "imgForeground[imgBackground] = 0\n",
    "binary = gaussian(imgScaled) <=threshval\n",
    "imgFilt = binary\n",
    "edgePic = canny(frangi(gaussian(imgScaled)))\n",
    "\n",
    "val = threshold_minimum(imgScaled)\n",
    "binary = imgScaled <= val\n",
    "plt.imshow(canny(gaussian(binary)))\n",
    "\n",
    "plt.imshow(imgScaled[int(imgScaled.shape[0]/4):-int(imgScaled.shape[0]/4),int(imgScaled.shape[1]/4):-int(imgScaled.shape[1]/4)])\n",
    "\n",
    "# blobs = blob_doh(gaussian(imgForeground),min_sigma=1.0,max_sigma=30,log_scale=False)\n",
    "\n",
    "# nonEdgeBlobs = np.logical_and.reduce((np.all(blobs!=0,axis=1),blobs[:,0]!=imgScaled.shape[0]-1,blobs[:,1]!=imgScaled.shape[1]-1))\n",
    "\n",
    "# blobs = blobs[nonEdgeBlobs]\n",
    "# print(imgScaled.shape)\n",
    "# print(len(blobs))\n",
    "# print(blobs)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(9, 3))\n",
    "# ax.imshow(imgScaled, interpolation='nearest')\n",
    "# for blob in blobs:\n",
    "#     y, x, r = blob\n",
    "#     c = plt.Circle((x, y), r, color='red', linewidth=2, fill=False)\n",
    "#     ax.add_patch(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features from All Images\n",
    "Using the `extractImageFeatures` function, we will extract the features from all images in the dataset, and then split the dataset into training and test sets. We have used a 50/50 split of training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from multiprocessing import Pool\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in folder 1 of 50 folders...\n",
      "Looking in folder 2 of 50 folders...\n",
      "Looking in folder 3 of 50 folders...\n",
      "Looking in folder 4 of 50 folders...\n",
      "Looking in folder 5 of 50 folders...\n",
      "Looking in folder 6 of 50 folders...\n",
      "Looking in folder 7 of 50 folders...\n",
      "Looking in folder 8 of 50 folders...\n",
      "Looking in folder 9 of 50 folders...\n",
      "Looking in folder 10 of 50 folders...\n",
      "Looking in folder 11 of 50 folders...\n",
      "Looking in folder 12 of 50 folders...\n",
      "Looking in folder 13 of 50 folders...\n",
      "Looking in folder 14 of 50 folders...\n",
      "Looking in folder 15 of 50 folders...\n",
      "Looking in folder 16 of 50 folders...\n",
      "Looking in folder 17 of 50 folders...\n",
      "Looking in folder 18 of 50 folders...\n",
      "Looking in folder 19 of 50 folders...\n",
      "Looking in folder 20 of 50 folders...\n",
      "Looking in folder 21 of 50 folders...\n",
      "Looking in folder 22 of 50 folders...\n",
      "Looking in folder 23 of 50 folders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:63: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:63: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: divide by zero encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in folder 24 of 50 folders...\n",
      "Looking in folder 25 of 50 folders...\n",
      "Looking in folder 26 of 50 folders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:63: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: divide by zero encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in folder 27 of 50 folders...\n",
      "Looking in folder 28 of 50 folders...\n",
      "Looking in folder 29 of 50 folders...\n",
      "Looking in folder 30 of 50 folders...\n",
      "Looking in folder 31 of 50 folders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:63: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: divide by zero encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in folder 32 of 50 folders...\n",
      "Looking in folder 33 of 50 folders...\n",
      "Looking in folder 34 of 50 folders...\n",
      "Looking in folder 35 of 50 folders...\n",
      "Looking in folder 36 of 50 folders...\n",
      "Looking in folder 37 of 50 folders...\n",
      "Looking in folder 38 of 50 folders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:63: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:63: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: divide by zero encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in folder 39 of 50 folders...\n",
      "Looking in folder 40 of 50 folders...\n",
      "Looking in folder 41 of 50 folders...\n",
      "Looking in folder 42 of 50 folders...\n",
      "Looking in folder 43 of 50 folders...\n",
      "Looking in folder 44 of 50 folders...\n",
      "Looking in folder 45 of 50 folders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:63: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/home/sam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: divide by zero encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in folder 46 of 50 folders...\n",
      "Looking in folder 47 of 50 folders...\n",
      "Looking in folder 48 of 50 folders...\n",
      "Looking in folder 49 of 50 folders...\n",
      "Looking in folder 50 of 50 folders...\n",
      "355.85859656333923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# initialize the test and training sets\n",
    "\n",
    "pathToImageFolders = \"50_categories/\"\n",
    "eachFolder = glob(pathToImageFolders+\"*/\")\n",
    "\n",
    "train_size = 0.5 # ratio of training dataset to total dataset\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "\n",
    "# open up 16 processes to extract features in parallel\n",
    "num_processes = 16\n",
    "pool = Pool(processes=num_processes)\n",
    "\n",
    "starttime = time() # let's time how long this takes\n",
    "# go through each folder and extract features from each image in the folder\n",
    "for iFolder,folder in enumerate(eachFolder):\n",
    "    print(f\"Looking in folder {iFolder+1} of {len(eachFolder)} folders...\")\n",
    "    filesInFolder = glob(folder+\"*.jpg\")\n",
    "    # extract image features from each file in the folder\n",
    "    parallelFeatures = pool.map(extractImageFeatures,filesInFolder)\n",
    "    # store the image features in X and the image categories in Y\n",
    "    X.append(np.vstack(parallelFeatures))\n",
    "    Y.append(np.repeat(folder[len(pathToImageFolders):-1],len(filesInFolder))) # image categories come from folder names\n",
    "\n",
    "print(time()-starttime) # print the time elapsed\n",
    "\n",
    "pool.terminate()\n",
    "del pool\n",
    "\n",
    "# put all of the features and categories into single arrays\n",
    "X = np.vstack(X)\n",
    "Y = np.concatenate(Y)\n",
    "\n",
    "# split into test and train sets using the specified train_size\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,train_size=train_size,stratify=Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build A Random Forest Classifier\n",
    "Using the features extracted from the images in the training set, we will train our random forest classifier and see how accurate it is when applied to our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply a random forest classifier to our training set\n",
    "randforclf = RandomForestClassifier(n_estimators=50)\n",
    "randforclf.fit(X_train,Y_train)\n",
    "pred_rf = randforclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.30207351555136663\n",
      "Accuracy from cross-validation: 0.3162290398474747 (+/- 0.0061073868962440315)\n"
     ]
    }
   ],
   "source": [
    "# use the test set to calculate some accuracy metrics\n",
    "print(f\"Score: {metrics.accuracy_score(Y_test,pred_rf)}\")\n",
    "scores = cross_val_score(randforclf,X,Y,cv=5,groups=Y)\n",
    "print(f\"Accuracy from cross-validation: {np.mean(scores)} (+/- {np.std(scores)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08974201, 0.02913157, 0.03079588, 0.02727185, 0.02962395,\n",
       "       0.02954755, 0.02575988, 0.02315035, 0.0224068 , 0.02814779,\n",
       "       0.02700264, 0.02505088, 0.02451073, 0.02903308, 0.0506323 ,\n",
       "       0.02624541, 0.02666196, 0.03035106, 0.02781869, 0.02736479,\n",
       "       0.0266962 , 0.02764258, 0.02673588, 0.03106112, 0.0255416 ,\n",
       "       0.02451733, 0.02741318, 0.02538112, 0.02816875, 0.03258217,\n",
       "       0.02896516, 0.03626271, 0.02878302])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the most important features?\n",
    "randforclf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the above cell that the most important features are the 1st, 15th, and 32nd features. These correspond to:\n",
    "\n",
    "| Feature | Importance |  \n",
    "| :------- | :---------- |  \n",
    "| Aspect Ratio | 0.08974201 |  \n",
    "| Shannon Entropy | 0.0506323 |  \n",
    "| Ratio of Number of Lines to Edge Length | 0.03626271|  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to Random Guessing\n",
    "Here, we apply a dummy classifier to the dataset that randomly guesses based on the distribution of categories in the training set. This is used to compare the performance of the random forest classifier that was trained using the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use a dummy classifier that randomly guesses what the image is to compare to our classifier\n",
    "dummyclf = DummyClassifier(strategy=\"prior\",random_state=42)\n",
    "dummyclf.fit(X_train,Y_train)\n",
    "dummypred_rf = dummyclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.12535344015080113\n",
      "Accuracy from cross-validation: 0.12562240614744166 (+/- 0.0018389617183439597)\n"
     ]
    }
   ],
   "source": [
    "# use the test set to calculate some accuracy metrics\n",
    "print(f\"Score: {metrics.accuracy_score(Y_test,dummypred_rf)}\")\n",
    "dummyscores = cross_val_score(dummyclf,X,Y,cv=5,groups=Y)\n",
    "print(f\"Accuracy from cross-validation: {np.mean(dummyscores)} (+/- {np.std(dummyscores)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, using cross validation, our **random forest classifier** had an accuracy of **31.6 $\\pm$ 0.6 %**.  \n",
    "A **dummy classifier** that randomly guesses the category based on the distribution of each category has an accuracy of **12.6 $\\pm$ 0.2 %**. \n",
    "\n",
    "Thus, I was able to achieve an accuracy that was a factor of nearly **3 times better than randomly guessing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Save the Random Forest Classifier\n",
    "**NOTE**: I realize that Pickle is not a recommended way of storing models. However, since this is a short term assignment, I believe it should be fine to use Pickle on this model for the grader to use later. I was going to use Joblib, but I read [here](http://scikit-learn.org/stable/modules/model_persistence.html) that \n",
    "\n",
    ">Since a model internal representation may be different on two different architectures, dumping a model on one architecture and loading it on another architecture is not supported.  \n",
    "\n",
    "So, I'm worried that using Joblib wouldn't allow the grader to load the file, if we end up having different architectures. Thus, I've elected to just use Pickle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('randforclf.pkl', 'wb') as f:\n",
    "    pickle.dump(randforclf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Random Forest Classifier and Run Predictions on a Directory\n",
    "**NOTE**: You need to run the first two cells of this notebook to use the `run_final_classifier`, as we need to import the `extractImageFeatures` function and the various functions/modules it uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from os.path import basename\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def run_final_classifier(pathToDirectory):\n",
    "    \"\"\"\n",
    "    Function to Extract Features from All Images in a Directory\n",
    "        \n",
    "        This function takes in a path to a directory of images, extracts features from each images in the directory,\n",
    "        prints the filenames and predicted category to a file called output.txt, and returns the predictions\n",
    "        of the model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pathToDirectory : str\n",
    "        The path to the directory that contains all images from which we will extract features from.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pred_rf : numpy.ndarray\n",
    "        An array that stores all of the predictions for the test data in the directory specified.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # open up 16 processes to extract features in parallel\n",
    "    num_processes = 16\n",
    "    pool = Pool(processes=num_processes)\n",
    "    \n",
    "    filesInFolder = glob(pathToDirectory+\"*.jpg\")\n",
    "    filenames = [basename(x) for x in filesInFolder]\n",
    "    \n",
    "    # extract image features from each file in the folder\n",
    "    X_test = pool.map(extractImageFeatures,filesInFolder)\n",
    "    \n",
    "    pool.terminate()\n",
    "    \n",
    "    X_test = np.vstack(X_test)\n",
    "    \n",
    "    with open('randforclf.pkl', 'rb') as f:\n",
    "        randforclf = pickle.load(f)\n",
    "    \n",
    "    pred_rf = randforclf.predict(X_test)\n",
    "    \n",
    "    with open(\"output.txt\",\"w\") as f:\n",
    "        f.write(\"filename\\tpredicted_class\\n\")\n",
    "        f.write(\"-----------------------------------------------------------------\\n\")\n",
    "        for iFile,filename in enumerate(filenames):\n",
    "            f.write(f\"{filename}\\t{pred_rf[iFile]}\\n\")\n",
    "            \n",
    "    return pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this path to the path to the validation dataset\n",
    "pathToDirectory = \"50_categories/airplanes/\"\n",
    "\n",
    "# run the final classifier on the validation dataset, which will\n",
    "pred_rf = run_final_classifier(pathToDirectory) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
